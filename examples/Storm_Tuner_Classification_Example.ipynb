{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This uses the latest SToRM Tuner package from this web site\n",
    "https://github.com/ben-arnao/stochasticmutatortuner\n",
    "It is Open Source and it is excellent in speed and versatility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "#from tuner import Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from storm.tuner import Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>893783</td>\n",
       "      <td>0</td>\n",
       "      <td>11.70</td>\n",
       "      <td>19.11</td>\n",
       "      <td>74.33</td>\n",
       "      <td>418.7</td>\n",
       "      <td>0.08814</td>\n",
       "      <td>0.05253</td>\n",
       "      <td>0.015830</td>\n",
       "      <td>0.011480</td>\n",
       "      <td>...</td>\n",
       "      <td>12.61</td>\n",
       "      <td>26.55</td>\n",
       "      <td>80.92</td>\n",
       "      <td>483.1</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.10870</td>\n",
       "      <td>0.079150</td>\n",
       "      <td>0.05741</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>0.06958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>898431</td>\n",
       "      <td>1</td>\n",
       "      <td>19.68</td>\n",
       "      <td>21.68</td>\n",
       "      <td>129.90</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>0.09797</td>\n",
       "      <td>0.13390</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>...</td>\n",
       "      <td>22.75</td>\n",
       "      <td>34.66</td>\n",
       "      <td>157.60</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.34580</td>\n",
       "      <td>0.473400</td>\n",
       "      <td>0.22550</td>\n",
       "      <td>0.4045</td>\n",
       "      <td>0.07918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>854039</td>\n",
       "      <td>1</td>\n",
       "      <td>16.13</td>\n",
       "      <td>17.88</td>\n",
       "      <td>107.00</td>\n",
       "      <td>807.2</td>\n",
       "      <td>0.10400</td>\n",
       "      <td>0.15590</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.077520</td>\n",
       "      <td>...</td>\n",
       "      <td>20.21</td>\n",
       "      <td>27.26</td>\n",
       "      <td>132.70</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.14460</td>\n",
       "      <td>0.58040</td>\n",
       "      <td>0.527400</td>\n",
       "      <td>0.18640</td>\n",
       "      <td>0.4270</td>\n",
       "      <td>0.12330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>901034302</td>\n",
       "      <td>0</td>\n",
       "      <td>12.54</td>\n",
       "      <td>18.07</td>\n",
       "      <td>79.42</td>\n",
       "      <td>491.9</td>\n",
       "      <td>0.07436</td>\n",
       "      <td>0.02650</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>...</td>\n",
       "      <td>13.72</td>\n",
       "      <td>20.98</td>\n",
       "      <td>86.82</td>\n",
       "      <td>585.7</td>\n",
       "      <td>0.09293</td>\n",
       "      <td>0.04327</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>0.01635</td>\n",
       "      <td>0.2233</td>\n",
       "      <td>0.05521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91550</td>\n",
       "      <td>0</td>\n",
       "      <td>11.74</td>\n",
       "      <td>14.69</td>\n",
       "      <td>76.31</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0.08099</td>\n",
       "      <td>0.09661</td>\n",
       "      <td>0.067260</td>\n",
       "      <td>0.026390</td>\n",
       "      <td>...</td>\n",
       "      <td>12.45</td>\n",
       "      <td>17.60</td>\n",
       "      <td>81.25</td>\n",
       "      <td>473.8</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.27930</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.10560</td>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.09879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0     893783          0        11.70         19.11           74.33      418.7   \n",
       "1     898431          1        19.68         21.68          129.90     1194.0   \n",
       "2     854039          1        16.13         17.88          107.00      807.2   \n",
       "3  901034302          0        12.54         18.07           79.42      491.9   \n",
       "4      91550          0        11.74         14.69           76.31      426.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.08814           0.05253        0.015830             0.011480   \n",
       "1          0.09797           0.13390        0.186300             0.110300   \n",
       "2          0.10400           0.15590        0.135400             0.077520   \n",
       "3          0.07436           0.02650        0.001194             0.005449   \n",
       "4          0.08099           0.09661        0.067260             0.026390   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         12.61          26.55            80.92       483.1   \n",
       "1  ...         22.75          34.66           157.60      1540.0   \n",
       "2  ...         20.21          27.26           132.70      1261.0   \n",
       "3  ...         13.72          20.98            86.82       585.7   \n",
       "4  ...         12.45          17.60            81.25       473.8   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0           0.12230            0.10870         0.079150               0.05741   \n",
       "1           0.12180            0.34580         0.473400               0.22550   \n",
       "2           0.14460            0.58040         0.527400               0.18640   \n",
       "3           0.09293            0.04327         0.003581               0.01635   \n",
       "4           0.10730            0.27930         0.269000               0.10560   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.3487                  0.06958  \n",
       "1          0.4045                  0.07918  \n",
       "2          0.4270                  0.12330  \n",
       "3          0.2233                  0.05521  \n",
       "4          0.2604                  0.09879  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = '.'\n",
    "sep=','\n",
    "filename = 'breast_cancer.csv'\n",
    "df=pd.read_csv(datapath+filename, sep=sep)\n",
    "df['diagnosis'] = df['diagnosis'].map({'B':0,'M':1})\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.iloc[:,2:] ## independent features\n",
    "y=df.iloc[:,1] ## dependent features\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # example of model-wide unordered categorical parameter\n",
    "    activation_fn = hp.Param('activation', ['relu', 'selu', 'elu'])\n",
    "\n",
    "    # example of per-block parameter\n",
    "    model.add(Dense(hp.Param('kernel_size_' + str(0), \n",
    "                             sorted(np.linspace(64,200,100).astype(int),reverse=True), \n",
    "                             ordered=True)))\n",
    "\n",
    "    model.add(Activation(activation_fn))\n",
    "\n",
    "    # example of boolean param\n",
    "    if hp.Param('use_batch_norm', [True, False]):\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "    if hp.Param('use_dropout', [True, False]):\n",
    "\n",
    "        # example of nested param\n",
    "        #\n",
    "        # this param will not affect the configuration hash, if this block of code isn't executed\n",
    "        # this is to ensure we do not test configurations that are functionally the same\n",
    "        # but have different values for unused parameters\n",
    "        model.add(Dropout(hp.Param('dropout_value', [0.1, 0.2, 0.3, 0.4, 0.5], ordered=True)))\n",
    "    kernel_size =  hp.values['kernel_size_' + str(0)]\n",
    "    # example of inline ordered parameter\n",
    "    for x in range(hp.Param('num_layers', [1, 2, 3], ordered=True)):\n",
    "\n",
    "        kernel_size = int(0.75*kernel_size)\n",
    "        # example of per-block parameter\n",
    "        model.add(Dense(kernel_size))\n",
    "        \n",
    "        model.add(Activation(activation_fn))\n",
    "\n",
    "        # example of boolean param\n",
    "        if hp.Param('use_batch_norm', [True, False]):\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        if hp.Param('use_dropout', [True, False]):\n",
    "\n",
    "            # example of nested param\n",
    "            #\n",
    "            # this param will not affect the configuration hash, if this block of code isn't executed\n",
    "            # this is to ensure we do not test configurations that are functionally the same\n",
    "            # but have different values for unused parameters\n",
    "            model.add(Dropout(hp.Param('dropout_value', [0.1, 0.2, 0.3, 0.4, 0.5], ordered=True)))\n",
    "    output_activation = 'sigmoid'\n",
    "    num_predicts = 2\n",
    "    model.add(Dense(num_predicts, activation=output_activation))\n",
    "\n",
    "    loss_fn = 'sparse_categorical_crossentropy'\n",
    "    model.compile(loss=loss_fn, optimizer='Adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "def custom_score_function(x_train, y_train, x_valid, y_valid, model, batch_size,):\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.00001, patience=10,\n",
    "                        verbose=0, mode='max', baseline=None, restore_best_weights=True)\n",
    "\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=25, batch_size=batch_size, \n",
    "                        validation_data=(x_valid,y_valid), callbacks=[es],\n",
    "                        verbose=0)\n",
    "    # here we can defined custom logic to assign a score to a configuration\n",
    "    return np.mean(history.history['loss'][-5:])\n",
    "\n",
    "class MyTuner(Tuner):\n",
    "\n",
    "    def run_trial(self, trial, X_train, y_train, X_test, y_test, \n",
    "                  ):\n",
    "        hp = trial.hyperparameters\n",
    "        model = build_model(hp)\n",
    "        # here we can access params generated in the builder function\n",
    "        # example of supplementary paramteter that will be accessed elsewhere  ##\n",
    "        batch_limit = int(min(2000, X_train.shape[0]))\n",
    "        batch_nums = int(max(200, X_train.shape[0]))\n",
    "        batch_size = hp.Param('batch_size', sorted(np.linspace(32,\n",
    "                                batch_limit,batch_nums).astype(int),reverse=True),\n",
    "                                 ordered=True)\n",
    "\n",
    "        score = custom_score_function(X_train,\n",
    "                                      y_train,\n",
    "                                      X_test,\n",
    "                                      y_test,\n",
    "                                      model=model,\n",
    "                                      batch_size=batch_size,\n",
    "                                     )\n",
    "        self.score_trial(trial, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new tuner initialized\n"
     ]
    }
   ],
   "source": [
    "tuner = MyTuner(project_dir='C:/',\n",
    "                build_fn=build_model,\n",
    "                objective_direction='min',\n",
    "                init_random=5,\n",
    "                max_iters=10,\n",
    "                randomize_axis_factor=0.5,\n",
    "                overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- OPTIMIZING HYPERPARAMETERS --------\n",
      "\n",
      "<><><> NEW BEST! <><><>\n",
      "\tactivation : relu\n",
      "\tbatch_size : 383\n",
      "\tdropout_value : 0.4\n",
      "\tkernel_size_0 : 176\n",
      "\tnum_layers : 3\n",
      "\tuse_batch_norm : True\n",
      "\tuse_dropout : True\n",
      "1 | score: 0.39704698\n",
      "2 | score: 0.4659237\n",
      "3 | score: 30.38740196\n",
      "<><><> NEW BEST! <><><>\n",
      "\tactivation : relu\n",
      "\tbatch_size : 325\n",
      "\tkernel_size_0 : 66\n",
      "\tnum_layers : 2\n",
      "\tuse_batch_norm : True\n",
      "\tuse_dropout : False\n",
      "4 | score: 0.19108576\n",
      "5 | score: 10.6162756\n",
      "6 | score: 0.30448833\n",
      "<><><> NEW BEST! <><><>\n",
      "\tactivation : elu\n",
      "\tbatch_size : 325\n",
      "\tkernel_size_0 : 66\n",
      "\tnum_layers : 2\n",
      "\tuse_batch_norm : True\n",
      "\tuse_dropout : False\n",
      "7 | score: 0.16273599\n",
      "<><><> NEW BEST! <><><>\n",
      "\tactivation : elu\n",
      "\tbatch_size : 325\n",
      "\tkernel_size_0 : 66\n",
      "\tnum_layers : 1\n",
      "\tuse_batch_norm : True\n",
      "\tuse_dropout : False\n",
      "8 | score: 0.1547011\n",
      "9 | score: 0.5016996\n",
      "10 | score: 0.26583421\n",
      "11 | score: 0.1771562\n",
      "tuner finished\n"
     ]
    }
   ],
   "source": [
    "# parameters passed through 'search' go directly to the 'run_trial' method\n",
    "tuner.search(X_train, y_train, X_test, y_test,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(tuner.get_best_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 10\n",
    "val_monitor = 'val_loss'\n",
    "lr_patience = max(2,int(patience*1.5))\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor=val_monitor, factor=0.25,\n",
    "                patience=lr_patience, min_lr=1e-6, mode='auto', min_delta=0.00001, \n",
    "                                  cooldown=0, verbose=1)\n",
    "es = callbacks.EarlyStopping(monitor=val_monitor, min_delta=0.00001, patience=10,\n",
    "                    verbose=0, mode='min', baseline=None, restore_best_weights=True)\n",
    "callbacks_list = [es, rlr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 68ms/step - loss: 0.5519 - accuracy: 0.6809 - val_loss: 2.7587 - val_accuracy: 0.3743\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2168 - accuracy: 0.9115 - val_loss: 2.5830 - val_accuracy: 0.3860\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1844 - accuracy: 0.9232 - val_loss: 2.4345 - val_accuracy: 0.3918\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1794 - accuracy: 0.9252 - val_loss: 2.1829 - val_accuracy: 0.3918\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1736 - accuracy: 0.9303 - val_loss: 1.8850 - val_accuracy: 0.4211\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1665 - accuracy: 0.9311 - val_loss: 1.6527 - val_accuracy: 0.4386\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1599 - accuracy: 0.9340 - val_loss: 1.4695 - val_accuracy: 0.4561\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1554 - accuracy: 0.9319 - val_loss: 1.3168 - val_accuracy: 0.4737\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1526 - accuracy: 0.9333 - val_loss: 1.1730 - val_accuracy: 0.5088\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1496 - accuracy: 0.9353 - val_loss: 1.0491 - val_accuracy: 0.5263\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1459 - accuracy: 0.9362 - val_loss: 0.9534 - val_accuracy: 0.5556\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1427 - accuracy: 0.9350 - val_loss: 0.8861 - val_accuracy: 0.5673\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1401 - accuracy: 0.9334 - val_loss: 0.8374 - val_accuracy: 0.5848\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1386 - accuracy: 0.9348 - val_loss: 0.7910 - val_accuracy: 0.6023\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1371 - accuracy: 0.9389 - val_loss: 0.7403 - val_accuracy: 0.6433\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1353 - accuracy: 0.9409 - val_loss: 0.6815 - val_accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1334 - accuracy: 0.9440 - val_loss: 0.6233 - val_accuracy: 0.6725\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1314 - accuracy: 0.9440 - val_loss: 0.5696 - val_accuracy: 0.7018\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1295 - accuracy: 0.9440 - val_loss: 0.5334 - val_accuracy: 0.7368\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1284 - accuracy: 0.9461 - val_loss: 0.5220 - val_accuracy: 0.7544\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1272 - accuracy: 0.9492 - val_loss: 0.5096 - val_accuracy: 0.7836\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1257 - accuracy: 0.9492 - val_loss: 0.4873 - val_accuracy: 0.8070\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1244 - accuracy: 0.9544 - val_loss: 0.4726 - val_accuracy: 0.8304\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1232 - accuracy: 0.9544 - val_loss: 0.4591 - val_accuracy: 0.8421\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1219 - accuracy: 0.9544 - val_loss: 0.4453 - val_accuracy: 0.8538\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1207 - accuracy: 0.9544 - val_loss: 0.4386 - val_accuracy: 0.8772\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1196 - accuracy: 0.9544 - val_loss: 0.4260 - val_accuracy: 0.8830\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1183 - accuracy: 0.9544 - val_loss: 0.4127 - val_accuracy: 0.8889\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1171 - accuracy: 0.9564 - val_loss: 0.4059 - val_accuracy: 0.8947\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1159 - accuracy: 0.9564 - val_loss: 0.3992 - val_accuracy: 0.9006\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1147 - accuracy: 0.9564 - val_loss: 0.3890 - val_accuracy: 0.9298\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1142 - accuracy: 0.9564 - val_loss: 0.3738 - val_accuracy: 0.9181\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1125 - accuracy: 0.9564 - val_loss: 0.3685 - val_accuracy: 0.9240\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1112 - accuracy: 0.9564 - val_loss: 0.3661 - val_accuracy: 0.9298\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1103 - accuracy: 0.9564 - val_loss: 0.3636 - val_accuracy: 0.9357\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1093 - accuracy: 0.9585 - val_loss: 0.3657 - val_accuracy: 0.9415\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1079 - accuracy: 0.9585 - val_loss: 0.3715 - val_accuracy: 0.9415\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1067 - accuracy: 0.9585 - val_loss: 0.3783 - val_accuracy: 0.9298\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1054 - accuracy: 0.9585 - val_loss: 0.3866 - val_accuracy: 0.9298\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1043 - accuracy: 0.9585 - val_loss: 0.3993 - val_accuracy: 0.9298\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1028 - accuracy: 0.9605 - val_loss: 0.4183 - val_accuracy: 0.9357\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1011 - accuracy: 0.9605 - val_loss: 0.4333 - val_accuracy: 0.9181\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1005 - accuracy: 0.9605 - val_loss: 0.4473 - val_accuracy: 0.9181\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0997 - accuracy: 0.9585 - val_loss: 0.4833 - val_accuracy: 0.9064\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.0984 - accuracy: 0.9626 - val_loss: 0.4961 - val_accuracy: 0.9064\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_EPOCHS = 50\n",
    "STEPS_PER_EPOCH = int(max(2,NUMBER_OF_EPOCHS/10))\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                epochs=NUMBER_OF_EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                callbacks=callbacks_list, validation_steps=STEPS_PER_EPOCH,\n",
    "               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_189 (Dense)            (None, 66)                2046      \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 66)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 66)                264       \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 49)                3283      \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 49)                196       \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 2)                 100       \n",
      "=================================================================\n",
      "Total params: 5,889\n",
      "Trainable params: 5,659\n",
      "Non-trainable params: 230\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = model.predict(X_test).argmax(axis=1)\n",
    "y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       108\n",
      "           1       0.93      0.89      0.91        63\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.94      0.93      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n",
      "[[104   4]\n",
      " [  7  56]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, mean_squared_error, confusion_matrix\n",
    "#np.sqrt(mean_squared_error(y_test, y_preds))\n",
    "print(classification_report(y_test, y_preds))\n",
    "print(confusion_matrix(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
