{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This uses the latest SToRM Tuner package from this web site\n",
    "https://github.com/ben-arnao/stochasticmutatortuner\n",
    "It is Open Source and it is excellent in speed and versatility!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "#from tuner import Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from storm.tuner import Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = ''\n",
    "sep='\\t'\n",
    "filename = 'boston.csv'\n",
    "df=pd.read_csv(datapath+filename, sep=sep)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,:-1] ## independent features\n",
    "y=df.iloc[:,-1] ## dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # example of model-wide unordered categorical parameter\n",
    "    activation_fn = hp.Param('activation', ['relu', 'selu', 'elu'])\n",
    "\n",
    "    # example of inline ordered parameter\n",
    "    for x in range(hp.Param('num_layers', [1, 2, 3], ordered=True)):\n",
    "\n",
    "        # example of per-block parameter\n",
    "        model.add(Dense(hp.Param('kernel_size_' + str(x), \n",
    "                                 sorted(np.linspace(32,200,100).astype(int),reverse=True), \n",
    "                                 ordered=True)))\n",
    "\n",
    "        model.add(Activation(activation_fn))\n",
    "\n",
    "        # example of boolean param\n",
    "        if hp.Param('use_batch_norm', [True, False]):\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        if hp.Param('use_dropout', [True, False]):\n",
    "\n",
    "            # example of nested param\n",
    "            #\n",
    "            # this param will not affect the configuration hash, if this block of code isn't executed\n",
    "            # this is to ensure we do not test configurations that are functionally the same\n",
    "            # but have different values for unused parameters\n",
    "            model.add(Dropout(hp.Param('dropout_value', [0.1, 0.2, 0.3, 0.4, 0.5], ordered=True)))\n",
    "\n",
    "    # example of supplementary paramteter that will be accessed elsewhere\n",
    "    hp.Param('batch_size', [24, 32, 64, 128], ordered=True)\n",
    "\n",
    "    loss_fn = 'mae'\n",
    "    model.compile(loss=loss_fn, optimizer='Adam', metrics=['mse','mae'])\n",
    "    return model\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "def custom_score_function(x_train, y_train, x_valid, y_valid, model, batch_size,):\n",
    "    \n",
    "    es = callbacks.EarlyStopping(monitor='val_mse', min_delta=0.00001, patience=10,\n",
    "                        verbose=0, mode='min', baseline=None, restore_best_weights=False)\n",
    "\n",
    "    history = model.fit(x_train, y_train, epochs=25, batch_size=batch_size, \n",
    "                        validation_data=(x_valid,y_valid), callbacks=[es],\n",
    "                        verbose=0)\n",
    "    # here we can defined custom logic to assign a score to a configuration\n",
    "    return np.mean(history.history['loss'][-5:])\n",
    "\n",
    "class MyTuner(Tuner):\n",
    "\n",
    "    def run_trial(self, trial, *args):\n",
    "        hp = trial.hyperparameters\n",
    "        model = build_model(hp)\n",
    "        X_train, y_train, X_test, y_test = args[0], args[1], args[2], args[3]\n",
    "        # here we can access params generated in the builder function\n",
    "        batch_size = hp.values['batch_size']\n",
    "\n",
    "        score = custom_score_function(X_train,\n",
    "                                      y_train,\n",
    "                                      X_test,\n",
    "                                      y_test,\n",
    "                                      model=model,\n",
    "                                      batch_size=batch_size,\n",
    "                                     )\n",
    "        self.score_trial(trial, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new tuner initialized\n"
     ]
    }
   ],
   "source": [
    "tuner = MyTuner(project_dir='C:/',\n",
    "                build_fn=build_model,\n",
    "                objective_direction='min',\n",
    "                init_random=5,\n",
    "                max_iters=10,\n",
    "                randomize_axis_factor=0.5,\n",
    "                overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- OPTIMIZING HYPERPARAMETERS --------\n",
      "\n",
      "<><><> NEW BEST! <><><>\n",
      "\tactivation : elu\n",
      "\tbatch_size : 24\n",
      "\tkernel_size_0 : 54\n",
      "\tnum_layers : 1\n",
      "\tuse_batch_norm : True\n",
      "\tuse_dropout : False\n",
      "1 | score: 22.61860313\n",
      "2 | score: 22.72087135\n",
      "<><><> NEW BEST! <><><>\n",
      "\tactivation : relu\n",
      "\tbatch_size : 128\n",
      "\tdropout_value : 0.2\n",
      "\tkernel_size_0 : 72\n",
      "\tkernel_size_1 : 127\n",
      "\tnum_layers : 2\n",
      "\tuse_batch_norm : False\n",
      "\tuse_dropout : True\n",
      "3 | score: 17.79927979\n",
      "4 | score: 17.98692856\n",
      "<><><> NEW BEST! <><><>\n",
      "\tactivation : selu\n",
      "\tbatch_size : 24\n",
      "\tdropout_value : 0.4\n",
      "\tkernel_size_0 : 69\n",
      "\tkernel_size_1 : 118\n",
      "\tnum_layers : 2\n",
      "\tuse_batch_norm : False\n",
      "\tuse_dropout : True\n",
      "5 | score: 14.29381237\n",
      "<><><> NEW BEST! <><><>\n",
      "\tactivation : selu\n",
      "\tbatch_size : 24\n",
      "\tdropout_value : 0.3\n",
      "\tkernel_size_0 : 69\n",
      "\tkernel_size_1 : 118\n",
      "\tnum_layers : 2\n",
      "\tuse_batch_norm : False\n",
      "\tuse_dropout : True\n",
      "6 | score: 11.62893715\n",
      "7 | score: 22.62281952\n",
      "8 | score: 11.70063953\n",
      "9 | score: 11.68217945\n",
      "10 | score: 11.74029427\n",
      "11 | score: 13.64981194\n",
      "tuner finished\n"
     ]
    }
   ],
   "source": [
    "# parameters passed through 'search' go directly to the 'run_trial' method\n",
    "tuner.search(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(tuner.get_best_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 10\n",
    "val_monitor = 'val_mse'\n",
    "lr_patience = max(2,int(patience*1.5))\n",
    "rlr = callbacks.ReduceLROnPlateau(monitor=val_monitor, factor=0.25,\n",
    "                patience=lr_patience, min_lr=1e-6, mode='auto', min_delta=0.00001, \n",
    "                                  cooldown=0, verbose=1)\n",
    "es = callbacks.EarlyStopping(monitor=val_monitor, min_delta=0.00001, patience=10,\n",
    "                    verbose=0, mode='min', baseline=None, restore_best_weights=True)\n",
    "callbacks_list = [es, rlr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 57ms/step - loss: 42.6758 - mse: 4429.5815 - mae: 42.6758 - val_loss: 28.6207 - val_mse: 1380.6838 - val_mae: 28.6207\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 35.5200 - mse: 2828.5357 - mae: 35.5200 - val_loss: 25.4212 - val_mse: 959.7036 - val_mae: 25.4212\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 31.2514 - mse: 1947.5880 - mae: 31.2514 - val_loss: 23.8353 - val_mse: 753.3897 - val_mae: 23.8353\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 28.2560 - mse: 1389.9870 - mae: 28.2560 - val_loss: 23.2181 - val_mse: 662.0891 - val_mae: 23.2181\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 26.3394 - mse: 1052.4190 - mae: 26.3394 - val_loss: 23.0263 - val_mse: 628.9810 - val_mae: 23.0263\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 25.2757 - mse: 880.9529 - mae: 25.2757 - val_loss: 23.1773 - val_mse: 628.1080 - val_mae: 23.1773\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 24.5859 - mse: 784.6209 - mae: 24.5859 - val_loss: 23.4625 - val_mse: 636.4367 - val_mae: 23.4625\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 24.1069 - mse: 716.8649 - mae: 24.1069 - val_loss: 23.6416 - val_mse: 643.2680 - val_mae: 23.6416\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 24.0234 - mse: 702.2192 - mae: 24.0234 - val_loss: 23.7258 - val_mse: 646.5359 - val_mae: 23.7258\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.9889 - mse: 696.7214 - mae: 23.9889 - val_loss: 23.7234 - val_mse: 646.0240 - val_mae: 23.7234\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 23.8801 - mse: 683.7731 - mae: 23.8801 - val_loss: 23.7138 - val_mse: 645.4777 - val_mae: 23.7138\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.7662 - mse: 675.5247 - mae: 23.7662 - val_loss: 23.7020 - val_mse: 644.8240 - val_mae: 23.7020\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23.6937 - mse: 670.4308 - mae: 23.6937 - val_loss: 23.6633 - val_mse: 643.1309 - val_mae: 23.6633\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.6317 - mse: 666.3969 - mae: 23.6317 - val_loss: 23.5959 - val_mse: 640.3048 - val_mae: 23.5959\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 23.5708 - mse: 663.6827 - mae: 23.5708 - val_loss: 23.5271 - val_mse: 637.3433 - val_mae: 23.5271\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 23.4622 - mse: 661.3644 - mae: 23.4622 - val_loss: 23.4833 - val_mse: 635.4407 - val_mae: 23.4833\n"
     ]
    }
   ],
   "source": [
    "NUMBER_OF_EPOCHS = 50\n",
    "STEPS_PER_EPOCH = int(max(2,NUMBER_OF_EPOCHS/10))\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                epochs=NUMBER_OF_EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                callbacks=callbacks_list, validation_steps=STEPS_PER_EPOCH,\n",
    "               shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 69)                966       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 69)                0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 69)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 118)               8260      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 118)               0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 118)               0         \n",
      "=================================================================\n",
      "Total params: 9,226\n",
      "Trainable params: 9,226\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
